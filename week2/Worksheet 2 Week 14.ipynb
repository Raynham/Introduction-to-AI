{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This worksheet covers the three supervised learning algorithms we looked at in week 14: k-nearest neighbours, linear regression, and the naive Bayes classifier. Similar to last week, you will do some work implementing your own versions of these algorithms, to ensure that you understand the details of them. You will also compare them with the implementations in scikit-learn to test your implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "Import key packages: NumPy, matplotlib, and any others that you prefer to work with. In general, when writing code, you will put all your import statements at the top. However, for these worksheets we will import as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: import NumPy and matplotlib here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: k-nearest neighbours classification\n",
    "In this question we will use the k-nearest neighbours algorithm to make predictions on the breast cancer Wisconsin dataset. This is a classification problem where the aim is to classify instances as either being malignant or benign based on the following 10 features:\n",
    "1. radius (mean of distances from center to points on the perimeter)\n",
    "2. texture (standard deviation of gray-scale values)\n",
    "3. perimeter\n",
    "4. area\n",
    "5. smoothness (local variation in radius lengths)\n",
    "6. compactness (perimeter squared/ area −1)\n",
    "7. concavity (severity of concave portions of the contour)\n",
    "8. concave points (number of concave portions of the contour)\n",
    "9. symmetry\n",
    "10. fractal dimension (‘coastline approximation’ −1)\n",
    "\n",
    "In this question you will (a) download the dataset from sklearn and store the data and targets in suitable variables, (b) separate your data into a training and test split, (c) write your own function to implement k-nearest neighbours, (d) check your implementation with that of sklearn. Wethen go on to (e) select the most appropriate value of $k$ using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a)\n",
    "Import the package `datasets` from `sklearn` and then load the breast cancer dataset (function is `load_breast_cancer()`). Save the data into a variable `X` and the targets into a variable `Y`. \n",
    "Take a look at the data in `X`. How many datapoints are there? How many features does each datapoint have? (Hint: use `np.shape`).\n",
    "Take a look at the targets. Is this suitable for a classification algorithm or a regression algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import suitable packages, load the dataset, and save data and targets into variables X and Y\n",
    "# import packages\n",
    "##TODO##\n",
    "from sklearn import datasets\n",
    "# load dataset and save data and targets into X and Y\n",
    "##TODO##\n",
    "X, Y = datasets.load_breast_cancer().data, datasets.load_breast_cancer().target\n",
    "print(np.shape(X))\n",
    "print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 569 datapoints, 30 features in the breast cancer dataset. The target values are 0 or 1, it is suitable for classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b)\n",
    "\n",
    "Use the function `train_test_split` from `sklearn.model_selection` to split your data into a training set and a held-out test set. Use a test set that is 0.2 of the original dataset. Set the parameter `random_state` to 10 to help with replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package train_test_split from sklearn.model_selection.\n",
    "# Split the dataset into Xtr, Xtest, Ytr, Ytest. Xtest and Ytest will form your held-out\n",
    "# test set. You will later split Xtr and Ytr into training and validation sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "Xtr, Xtest, Ytr, Ytest = split(X, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c) \n",
    "Recall from the lecture that the k-nearest neighbours algorithm runs as follows:\n",
    "\n",
    "Training step: Simply store the dataset\n",
    "\n",
    "Prediction step: Given a datapoint $\\vec{x}$:\n",
    " - **Find** the k datapoints $(\\vec{x}_i, y_i)$ where the distance from $\\vec{x}$ to $\\vec{x}_i$ is smallest\n",
    " - **Return** the majority class from the $y_i$\n",
    "   \n",
    " \n",
    "What, if anything, do you need to do for the training step?\n",
    "\n",
    "Write function(s) to implement the k-nearest neighbours prediction step. You may wish to break the procedure down into two functions `predict_datapoint` that makes a prediction for one datapoint and `predict_data` that loops over the whole dataset.\n",
    "\n",
    "To select the majority class from the nearest neighbours, you can use the function `scipy.stats.mode()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "# Write function(s) to implement the prediction step in k-nearest neighbours.\n",
    "# You can use the suggested structure below if desired.\n",
    "\n",
    "\n",
    "# predict_datapoint takes 4 arguments. pt (type: numpy array) is the datapoint we are making a prediction about,\n",
    "# Xtrain and Ytrain (numpy arrays) are training data and targets, k (int) is the number of neighbours.\n",
    "# Returns an integer which is the predicted class for pt\n",
    "def predict_datapoint(pt, Xtrain, Ytrain, k):\n",
    "    # For each datapoint in Xtrain, calculate the distance to pt and store\n",
    "    ##TODO##\n",
    "    distance_arr = []\n",
    "    for i in Xtrain:\n",
    "        distance_arr.append(np.sqrt(np.sum(np.square(pt-i))))\n",
    "    # Sort the list of distances (hint: use np.argsort)\n",
    "    ##TODO##\n",
    "    order_index = np.argsort(distance_arr)\n",
    "    # obtain the classes (in Ytrain) of the datapoints with the smallest distance to pt\n",
    "    ##TODO##\n",
    "    nei_labels = []\n",
    "    for i in range(k):\n",
    "        nei_labels.append(Ytrain[order_index[i]])\n",
    "    # return the mode of the classes\n",
    "    ##TODO##\n",
    "    return mode(nei_labels)[0][0]\n",
    "\n",
    "# predict_data takes 4 arguments: the test data Xtst (numpy array), the training data Xtrain (numpy array),\n",
    "# the training targets Ytrain (numpy array), and the number of neighbours k (int, default = 3).\n",
    "# Returns: predictions (array of int) for each point in Xtst\n",
    "\n",
    "\n",
    "def predict_data(Xtst, Xtrain, Ytrain, k=3):\n",
    "    # Loop over the datapoints in Xtst and store the prediction for that datapoint\n",
    "    ##TODO##\n",
    "    pred_tst = []\n",
    "    for pt in Xtst:\n",
    "        pred_tst.append(predict_datapoint(pt, Xtrain, Ytrain, k))\n",
    "    # Return the predictions\n",
    "    ##TODO##\n",
    "    return pred_tst\n",
    "# Predict values for the TRAINING data (we will not look at the test set yet)\n",
    "##TODO##\n",
    "pred_train = predict_data(Xtr,Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d)\n",
    "Now we can compare your implementation with the sklearn implementation (you should get the same results). Firstly import the classfifier `KNeighborsClassifier` from `sklearn.neighbors`. Instantiate the classifier with the same number of neighbours that you used previously. Fit the model and make a prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNeighborClassifier\n",
    "##TODO##\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Instantiate the classifier with 3 neighbors\n",
    "##TODO##\n",
    "knnClassi =  KNeighborsClassifier(n_neighbors=3)\n",
    "#Fit the classifier on the training data\n",
    "##TODO##\n",
    "knnClassi.fit(Xtr,Ytr)\n",
    "#Make a prediction on the training data\n",
    "##TODO##\n",
    "predTrain_sklearn = knnClassi.predict(Xtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether your predictions are the same as the predictions from `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "##TODO##\n",
    "print((predTrain_sklearn == pred_train).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built in metrics in sklearn to calculate the accuracy of your classifier on the TRAINING set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560439560439561"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO## \n",
    "knnClassi.score(Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part(e) Using cross-validation for model selection\n",
    "k-nearest neighbours has the parameter $k$, and we need to decide which is the best value of $k$ to use. Last week we talked about using cross-validation for model selection.\n",
    "\n",
    "We will use cross-validation on our training set to select the best value of $k$, in a range from 1 to 30.\n",
    "\n",
    "NB: use sklearn's version of k-NN rather than yours, since unless you have optimised yours it is probably too slow.\n",
    "\n",
    "Since we are using cross-validation for model selection we will cross-validate on the training set only.\n",
    "\n",
    "Procedure:\n",
    "        \n",
    " 1. Import `KFold` from `sklearn.model_selection`  \n",
    " 1. Instantiate `KFold` with 5 splits. Set the parameter `random_state` to help you reproduce your results if needed.\n",
    " 1. Set a variable `max_k` to 30  \n",
    " 1. Inititalise two variables to store the training accuracies and validation accuracies (these need to store max_k\\*5 accuracies)  \n",
    " 1. Loop over the values of k:  \n",
    "    1. Instantiate a k-nn classifier (Use the sklearn classifier) with the current value of k  \n",
    "    1. Loop over the cross-validation splits:  \n",
    "       1. fit the model on the current split of data  \n",
    "       1. make predictions  \n",
    "       1. calculate training and validation accuracy and store  \n",
    " 6. Calculate the mean training and validation accuracies across splits for each $k$\n",
    "\n",
    "Plot the mean training and validation accuracies. Which value of $k$ will you use? Why?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.96868132 0.95604396 0.95       0.95054945 0.94615385\n",
      " 0.94285714 0.9456044  0.94450549 0.94505495 0.93956044 0.93901099\n",
      " 0.93681319 0.93681319 0.93571429 0.93736264 0.93571429 0.93571429\n",
      " 0.93461538 0.93571429 0.93186813 0.93241758 0.92912088 0.92967033\n",
      " 0.92637363 0.92637363 0.92417582 0.92472527 0.92087912 0.92307692]\n",
      "[0.92087912 0.91648352 0.92747253 0.92747253 0.92087912 0.92747253\n",
      " 0.92307692 0.92747253 0.92967033 0.92967033 0.92967033 0.92747253\n",
      " 0.93186813 0.92967033 0.93186813 0.93186813 0.93186813 0.92967033\n",
      " 0.92747253 0.92747253 0.92747253 0.92527473 0.92527473 0.92307692\n",
      " 0.92307692 0.92307692 0.92087912 0.91868132 0.91868132 0.91648352]\n"
     ]
    }
   ],
   "source": [
    "# Use cross-validation to select the value of k\n",
    "# You can use the structure below if desired\n",
    "\n",
    "# Import KFold from sklearn.model_selection\n",
    "##TODO##\n",
    "from sklearn.model_selection import KFold\n",
    "# Instantiate KFold with 5 splits.\n",
    "# Set the parameter random_state to help you reproduce your results if needed.\n",
    "##TODO##\n",
    "kf = KFold(n_splits=5, random_state=63, shuffle=True)\n",
    "# Set a variable max_k to 30\n",
    "##TODO##\n",
    "max_k = 30\n",
    "# Inititalise two variables to store the\n",
    "# training accuracies and validation accuracies\n",
    "# (these need to store max_k*5 accuracies)\n",
    "##TODO##\n",
    "acc_training = [[] for _ in range(max_k)]\n",
    "acc_val = [[] for _ in range(max_k)]\n",
    "# Loop over the values of k:\n",
    "for k in range(max_k):\n",
    "\n",
    "    # Instantiate a k-nn classifier (Use the sklearn classifier)\n",
    "    # with the current value of k\n",
    "    ##TODO##\n",
    "    knn = KNeighborsClassifier(n_neighbors = k + 1)\n",
    "    # Loop over the cross-validation splits:\n",
    "    ##TODO##\n",
    "    for train_index, val_index in kf.split(Xtr):\n",
    "        x_train, x_val = Xtr[train_index], Xtr[val_index]\n",
    "        y_train, y_val = Ytr[train_index], Ytr[val_index]\n",
    "        # fit the model on the current split of data\n",
    "        ##TODO##\n",
    "        knn.fit(x_train, y_train)\n",
    "        # make predictions\n",
    "        ##TODO##\n",
    "        pred_y_train = knn.predict(x_train)\n",
    "        pred_y_val = knn.predict(x_val)\n",
    "        # calculate training and validation accuracy and store\n",
    "        ##TODO##\n",
    "        acc_training[k].append(knn.score(x_train,y_train))\n",
    "        acc_val[k].append(knn.score(x_val,y_val))\n",
    "# Calculate the mean training and validation accuracies across splits for each 𝑘\n",
    "##TODO##\n",
    "mean_acc_tr_eachk = np.mean(acc_training, axis=1)\n",
    "mean_acc_val_eachk = np.mean(acc_val, axis = 1)\n",
    "print(mean_acc_tr_eachk)\n",
    "print(mean_acc_val_eachk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the mean training and validation accuracies against each value of k. Which value of 𝑘 will you use? Why?\n",
    "##TODO##\n",
    "plt.plot(np.linspace(0, 30, 30),mean_acc_tr_eachk)\n",
    "plt.plot(np.linspace(0, 30, 30),mean_acc_val_eachk)\n",
    "plt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The naive Bayes classifier\n",
    "\n",
    "Recall from the lecture notes that the naive Bayes classifier works as follows. We are trying to approximate an unknown function $$f:\\Omega \\rightarrow \\mathcal{O}$$\n",
    "where $\\Omega$ is our feature space and our output space $\\mathcal{O} = \\{c_1, c_2, ... c_K\\}$ is a finite set of classes.\n",
    "\n",
    "The naive Bayes classifier does this by building a model that assigns the class label $\\hat{y} = c_k$ as follows:\n",
    "$$\n",
    "\\hat{y} = \\text{argmax}_k p(c_k)\\prod_i p(x_i| c_k)\n",
    "$$\n",
    "i.e., the $k$ that maximises this quantity.\n",
    "\n",
    "In practice, multiplying all the $p(x_i| c_k)$ together is going to give some very small values. Therefore, we can take the log to make it easier to compute:\n",
    "\\begin{align}\n",
    "\\hat{y} &= \\text{argmax}_k p(c_k)\\prod_i p(x_i| c_k)= \\text{argmax}_k log(p(c_k)\\prod_i p(x_i| c_k))\\\\\n",
    "&=\\text{argmax}_k log(p(c_k)) + \\sum_i log(p(x_i|c_k))\n",
    "\\end{align}\n",
    "\n",
    "If we choose that $p(x_i|c_k)$ is given by a normal distribution with mean $\\mu_k$ and variance $\\sigma_k^2$, then we obtain the following expression:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} &=\\text{argmax}_k \\log(p(c_k)) + \\sum_i \\log(p(x_i|c_k))\\\\\n",
    "&= \\text{argmax}_k \\log(p(c_k)) + \\sum_i \\log\\left(\\frac{1}{\\sigma_k\\sqrt{2\\pi}} exp\\left(\\frac{-(x-\\mu_k)^2}{2\\sigma_k}\\right)\\right)\\\\\n",
    "&= \\text{argmax}_k \\log(p(c_k)) - \\sum_i \\log\\left(\\sigma_k\\sqrt{2\\pi}\\right) - \\sum_i\\left(\\frac{(x-\\mu_k)^2}{2\\sigma_k}\\right) \\quad \\text{ log-likelihood}\n",
    "\\end{align}\n",
    "\n",
    "Expressing the values in terms of these sums means that they do not get so small, and it is less likely that there will be errors at the machine precision level.\n",
    "\n",
    "\n",
    "How do we implement this in practice? We assume that each probability $p(x_i| c_k)$ is given by some distribution, and then given a datapoint $\\vec{x}$, we plug the value into the equation for the distribution.\n",
    "\n",
    "In this question you will (a) implement your own version of the Gaussian naive Bayes classifier, (b) check your classifier against the implementation in sci-kit learn, (c) compare the accuracy of the naive Bayes classifier with the accuracy of the k-nearest neighbours classifier, and (d) run cross-validation to verify whether the kNN classfier or the Gaussian naive Bayes classifier performs better on this dataset.\n",
    "\n",
    "## Part (a) Implementing Gaussian naive Bayes\n",
    "For this question we will make the assumption that each feature is described by a normal (also called Gaussian) distribution. The procedure is as follows:\n",
    "1. Divide the training data by class\n",
    "2. Calculate mean and standard deviation per class and per feature\n",
    "4. For each datapoint in the validation set, calculate the log-likelihood for each class and for each feature (Hint: use the function `scipy.stats.norm.logpdf`)\n",
    "5. Combine these values together with the probability of the class according to the log-likelihood equation above\n",
    "6. Choose the class with the highest value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "##TODO##\n",
    "# Write your own implementation of naive Bayes applied to the breast cancer dataset.\n",
    "\n",
    "# If you wish you can follow the structure below\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Split the training data Xtr into training and validation sets with an 80:20 split.\n",
    "# Set the random state to help with reproducibility\n",
    "##TODO##\n",
    "x_train_bay, x_val_bay, y_train_bay, y_val_bay = split(\n",
    "    Xtr, Ytr, test_size=0.2, random_state=10)\n",
    "# Separate the training set into classes, so you have one set of data for each class\n",
    "##TODO##\n",
    "x_train_class0 = []\n",
    "x_train_class1 = []\n",
    "for index, val in enumerate(x_train_bay):\n",
    "    if y_train_bay[index] == 0:\n",
    "        x_train_class0.append(val)\n",
    "    if y_train_bay[index] == 1:\n",
    "        x_train_class1.append(val)\n",
    "\n",
    "# Calculate the means and standard deviations for each class, for each feature.\n",
    "# There are 30 features in the dataset, so you should have a 30-dimensional\n",
    "# array of means for each class and a 30-dimensional array of standard deviations\n",
    "# for each class. Remember that you can take the average across rows or columns of\n",
    "# a matrix by specifying axis = 1 or axis = 0\n",
    "##TODO##\n",
    "mean_class0 = np.mean(x_train_class0, axis=0)\n",
    "std_class0 = np.std(x_train_class0, axis=0)\n",
    "mean_class1 = np.mean(x_train_class1, axis=0)\n",
    "std_class1 = np.std(x_train_class1, axis=0)\n",
    "# Calculate the prior probability p(c_i) for each class\n",
    "##TODO##\n",
    "p_ci_class0 = len(x_train_class0)/len(x_train_bay)\n",
    "p_ci_class1 = len(x_train_class1)/len(x_train_bay)\n",
    "# Calculate the log-likelihood of each class for each datapoint in the validation set\n",
    "# Hint: you can use the function scipy.stats.norm.logpdf to help with this\n",
    "##TODO##\n",
    "log_likeli_class0 = []\n",
    "log_likeli_class1 = []\n",
    "for index, val in enumerate(x_val_bay):\n",
    "    log_likeli_class0.append(np.sum(norm(mean_class0, std_class0).logpdf(val)))\n",
    "    log_likeli_class1.append(np.sum(norm(mean_class1, std_class1).logpdf(val)))\n",
    "\n",
    "# Your predicted class is 0 if class 0 has the highest log-likelihood, and 1 if class 1\n",
    "# has the highest log-likelihood\n",
    "##TODO##\n",
    "\n",
    "pred_y_val = []\n",
    "for index, val in enumerate(log_likeli_class0):\n",
    "    if log_likeli_class1[index] > val:\n",
    "        pred_y_val.append(1)\n",
    "    else:\n",
    "        pred_y_val.append(0)\n",
    "print(pred_y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b) Checking results\n",
    "We now compare our results with the sklearn implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "##Import the classifier GaussianNB from sklearn.naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Instantiate the classifier (use the parameter var_smoothing=0.0),\n",
    "# fit, and predict the classes\n",
    "##TODO##\n",
    "\n",
    "naive_bayes = GaussianNB(var_smoothing=0.0)\n",
    "naive_bayes.fit(x_train_bay,y_train_bay)\n",
    "pred_y_val_bayes_sklearn = naive_bayes.predict(x_val_bay)\n",
    "print(pred_y_val_bayes_sklearn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compare your predicted classes with those of the sklearn implementation.\n",
    "# If they are not identical, this may be due to some differences in parameter setting. \n",
    "# They should be almost all the same, however.\n",
    "##TODO##\n",
    "print((pred_y_val_bayes_sklearn == pred_y_val).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c) Comparing k-nearest neighbours and Gaussian naive Bayes\n",
    "Now retrain the naive Bayes classifier using the original training set `Xtr`, `Ytr`.\n",
    "Also, retrain the k-nearest neighbours classifier using `Xtr` and `Ytr`. Use the value of $k$ that you decided on using cross-validation.\n",
    "You can use the sklearn implementations of knn and naive Bayes.\n",
    "\n",
    "Compute the accuracy of the naive Bayes classifier over the training set and the held-out test set.\n",
    "\n",
    "Compare with the accuracy of the k-nearest neighbours classifier on each set.\n",
    "\n",
    "Is it clear which classifier is the best on this dataset? why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for knn on training dataset: 0.9494505494505494:\n",
      "Accuracy for knn on test dataset: 0.9210526315789473:\n",
      "Accuracy for naive bayes on training dataset: 0.9274725274725275:\n",
      "Accuracy for naive bayes on test dataset: 0.956140350877193:\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the knn classifer with your chosen value of k\n",
    "##TODO##\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit the Gaussian naive Bayes classifier and the knn classifier on Xtr, Ytr\n",
    "##TODO##\n",
    "naive_bayes.fit(Xtr,Ytr)\n",
    "knn2.fit(Xtr,Ytr)\n",
    "# Make predictions for the training set and the test set\n",
    "##TODO##\n",
    "pred_train_knn = knn2.predict(Xtr)\n",
    "pred_test_knn = knn2.predict(Xtest)\n",
    "pred_train_naive_bayes = naive_bayes.predict(Xtr)\n",
    "pred_test_naive_bayes = naive_bayes.predict(Xtest)\n",
    "# Take a look at the accuracy scores\n",
    "##TODO##\n",
    "acc_train_knn = knn2.score(Xtr,Ytr)\n",
    "acc_test_knn = knn2.score(Xtest,Ytest)\n",
    "acc_train_naive_bayes = naive_bayes.score(Xtr,Ytr)\n",
    "acc_test_naive_bayes = naive_bayes.score(Xtest,Ytest)\n",
    "print(\"Accuracy for knn on training dataset: {}:\".format(acc_train_knn))\n",
    "print(\"Accuracy for knn on test dataset: {}:\".format(acc_test_knn))\n",
    "print(\"Accuracy for naive bayes on training dataset: {}:\".format(acc_train_naive_bayes))\n",
    "print(\"Accuracy for naive bayes on test dataset: {}:\".format(acc_test_naive_bayes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d) Using cross-validation for statistical validation\n",
    "Earlier we used cross-validation to select the model parameters we would be using. We can also use it another way: to provide statistical information about which model is best. We will set up cross-validation on the whole dataset, with 10 folds.\n",
    "\n",
    " - Compute the accuracy for each model on the test set on each fold.\n",
    " - Calculate the mean accuracy across folds. Which model performs best?\n",
    " - Make a box-plot of the spread of scores of each model. Is there a clear difference between model performance?\n",
    " - Perform a paired t-test on the accuracy scores. What can you conclude about the performance of the two models?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a k-fold cross-validation with 10 folds\n",
    "##TODO##\n",
    "kf = KFold(n_splits=10, random_state=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each fold, fit each model on the training data\n",
    "# and compute accuracy on the test data.\n",
    "##TODO##\n",
    "acc_test_knn_per_fold = []\n",
    "acc_test_naive_bayes_per_fold = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    naive_bayes.fit(X_train, Y_train)\n",
    "    knn2.fit(X_train, Y_train)\n",
    "    acc_test_knn_per_fold.append(knn2.score(X_test,Y_test))\n",
    "    acc_test_naive_bayes_per_fold.append(naive_bayes.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the corss validation with folds = 10\n",
      "The average of Accuracies for knn: 0.9333020050125315:\n",
      "The standard devation of Accuracies for knn: 0.04420923382606531:\n",
      "The average of Accuracies for naive bays: 0.9350250626566415:\n",
      "The standard devation of Accuracies for naive bays: 0.034190151101913195:\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and standard devation of the accuracies for each model.\n",
    "# Does one model perform better?\n",
    "##TODO##\n",
    "acc_mean_CV_knn = np.mean(acc_test_knn_per_fold)\n",
    "acc_std_CV_knn =  np.std(acc_test_knn_per_fold)\n",
    "acc_mean_CV_naive_bays = np.mean(acc_test_naive_bayes_per_fold)\n",
    "acc_std_CV_naive_bays = np.std(acc_test_naive_bayes_per_fold)\n",
    "print(\"After the corss validation with folds = 10\")\n",
    "print(\"The average of Accuracies for knn: {}:\".format(acc_mean_CV_knn))\n",
    "print(\"The standard devation of Accuracies for knn: {}:\".format(acc_std_CV_knn))\n",
    "print(\"The average of Accuracies for naive bays: {}:\".format(acc_mean_CV_naive_bays))\n",
    "print(\"The standard devation of Accuracies for naive bays: {}:\".format(acc_std_CV_naive_bays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average of Accuracies for naive bays is more than that for knn and the standard deviation of Accuracies for naive bays is less than that for knn. This means the naive bays model has generally better performance on this current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a boxplot of the accuracy scores. (Use plt.boxplot). \n",
    "# Is there a clear difference between the models?\n",
    "##TODO##\n",
    "labels = 'The accuracy for knn', 'The accuracy for naive bays'\n",
    "plt.boxplot([acc_test_knn_per_fold, acc_test_naive_bayes_per_fold], labels = labels, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of accuracies for knn varies more than that for naive bays. And most accuracy values for naive bays is over 0.93 and most accuracy values for knn is below 0.94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T statistics: -0.11388183314031669 P value: 0.9118314583498663\n"
     ]
    }
   ],
   "source": [
    "# Perform a paired t-test (you can use the function scipy.stats.ttest_rel). \n",
    "# What do you conclude about the performance of the two models?\n",
    "##TODO##\n",
    "from scipy.stats import ttest_rel\n",
    "t_sta, p_value = ttest_rel(acc_test_knn_per_fold,acc_test_naive_bayes_per_fold)\n",
    "print(\"T statistics: {}\".format(t_sta), \"P value: {}\".format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average of Accuracies for knn is more than that for naive bays, and we reject to admit these two models have the same performance under 95% confidence level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "In linear regression we make the assumption that the data $(x_i, y_i)$ can be modelled by a function of the form\n",
    "$$ \\hat{y_i} = f(\\vec{x}_i)= \\sum_j a_j x_{ij}  + b_i$$\n",
    "\n",
    "Recall that we can express this in a matrix format by:\n",
    "$$ \\hat{\\vec{y}} = f(X)= X\\Theta$$\n",
    "\n",
    "where \n",
    "$$ X=\\begin{pmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,n} &1 \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
    "x_{N,1} & x_{N,2} & \\ldots & x_{N,n} & 1\n",
    "\\end{pmatrix}, \\quad \\vec{y}=\\begin{pmatrix} y_1 \\\\ \\vdots \\\\y_N \\end{pmatrix}, \\quad \\Theta=\\begin{pmatrix} a_1 \\\\ \\vdots \\\\a_n\\\\b \\end{pmatrix}$$\n",
    "\n",
    "We saw in lectures that the optimal value of $\\Theta$ is given by setting\n",
    "$$ \\Theta = (X^T X)^{-1} X^T \\vec{y}$$\n",
    "\n",
    "The quantity $(X^T X)^{-1} X^T$ is called the psuedoinverse of X, and can be computed using the function `np.linalg.pinv`.\n",
    "\n",
    "We will (a) perform a linear regression on the diabetes dataset. You can load this dataset using the function `load_diabetes` from `sklearn.datasets`. (b) compute the mean squared error and the R^2, and (c) compare your results with the built in function in sklearn (`sklearn.linear_model.LinearRegresion()`). You should get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statments here\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a) Implementing linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "##TODO##\n",
    "from sklearn.datasets import load_diabetes\n",
    "X, Y = load_diabetes().data, load_diabetes().target\n",
    "print(np.shape(X),np.shape(Y))\n",
    "# Split the dataset into training and test, using test_size=0.2\n",
    "##TODO##\n",
    "Xtrain, Xtest, Ytrain, Ytest = split(X, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 11) (89, 11)\n"
     ]
    }
   ],
   "source": [
    "# Add a column of ones to Xtrain and Xtest for the intercept term\n",
    "##TODO##\n",
    "Xtrain = np.column_stack((Xtrain, np.linspace(1,1,len(Xtrain))[:,None]))\n",
    "Xtest = np.column_stack((Xtest, np.linspace(1,1,len(Xtest))[:,None]))\n",
    "print(np.shape(Xtrain),np.shape(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -3.89155188]\n",
      " [-225.62880027]\n",
      " [ 517.89525355]\n",
      " [ 328.32132183]\n",
      " [-727.23345563]\n",
      " [ 410.96799392]\n",
      " [  80.26601137]\n",
      " [ 218.18738355]\n",
      " [ 704.2805541 ]\n",
      " [  40.02247238]\n",
      " [ 152.25550535]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the value of the coefficients theta. You can use the function np.linalg.pinv\n",
    "##TODO##\n",
    "pseudo_inverse = np.linalg.pinv(Xtrain)\n",
    "theta = np.dot(pseudo_inverse,  Ytrain[:,None])\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b) Computing performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.0978202  208.21400551 186.40125844  82.48876916 163.39689627\n",
      " 126.17904513 126.17880476 264.70212482  78.54654307  73.56261024\n",
      " 124.46582144 142.22854705 166.4549438   98.5009742   49.71902346\n",
      " 223.51963411 143.44310503 110.50382605 202.53415354  78.49893296\n",
      " 191.80901882 243.20695862  75.88822445 214.90606332  55.73078912\n",
      " 158.0288059  157.54022573 158.88728076 166.2184483  107.63124236\n",
      " 276.82392637 179.20197197  60.48832138 157.42965435 218.98333103\n",
      " 182.29672873  70.84400009 186.74011272 285.13886084 196.19611072\n",
      " 202.26256246 145.38319546 215.02583484 124.55391269  80.17027241\n",
      "  98.99544054  82.02453761  83.40439369 289.99388729 134.33663141\n",
      " 112.1313993  152.32625919 109.90441466 226.28134724 245.74116064\n",
      "  85.56172621 122.28262271 139.20254207 198.95361934 120.92252444\n",
      " 179.99231965 106.43580454 123.03066928  96.46348156  94.96521004\n",
      " 230.01995973 175.10428431  91.2918623  167.79340958 121.57123563\n",
      " 165.20563345 181.26779154  65.1051729   72.81485938 231.35619415\n",
      " 185.78771152 173.68883444 158.22007536 108.88134149 164.4597236\n",
      " 182.06381167 124.68118663 206.58693233 147.68873424 155.35855424\n",
      " 151.40752238 140.07914902  89.42949429 115.09720605]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction on the test set by applying the coefficients theta to the test set\n",
    "##TODO##\n",
    "pred_y_test = np.dot(Xtest,theta)\n",
    "print(pred_y_test.T[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200. 202.  67.  80. 151. 145.  65. 308.  42.  92. 150. 202. 184. 101.\n",
      "  47. 237.  88. 152. 109.  89. 163. 274. 138. 275.  63. 154. 131.  91.\n",
      " 128. 129. 243. 200.  72. 185. 296. 144.  75. 175. 281. 292. 292. 214.\n",
      " 275.  92.  65.  31.  53.  51. 258.  40.  69.  86. 142. 128. 243.  55.\n",
      " 144. 230. 265.  63. 217. 102.  66. 101. 137. 261. 147.  64. 252.  59.\n",
      " 220. 126.  43.  48. 217. 164. 143. 206.  72. 110. 244.  51.  52. 302.\n",
      " 276. 150. 124. 114. 179.]\n"
     ]
    }
   ],
   "source": [
    "print(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2911.827951689161 0.5341962544929233\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error and the R^2. \n",
    "# You can use the built in functions from sklearn\n",
    "from sklearn import metrics\n",
    "##TODO##\n",
    "mse = metrics.mean_squared_error(Ytest,pred_y_test)\n",
    "r2 = metrics.r2_score(Ytest,pred_y_test)\n",
    "print(mse,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c) Checking results\n",
    "Compare your results with the built in function `sklearn.linear_model.LinearRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the linear regression\n",
    "##TODO##\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "linear_regression = lr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.0978202  208.21400551 186.40125844  82.48876916 163.39689627\n",
      " 126.17904513 126.17880476 264.70212482  78.54654307  73.56261024\n",
      " 124.46582144 142.22854705 166.4549438   98.5009742   49.71902346\n",
      " 223.51963411 143.44310503 110.50382605 202.53415354  78.49893296\n",
      " 191.80901882 243.20695862  75.88822445 214.90606332  55.73078912\n",
      " 158.0288059  157.54022573 158.88728076 166.2184483  107.63124236\n",
      " 276.82392637 179.20197197  60.48832138 157.42965435 218.98333103\n",
      " 182.29672873  70.84400009 186.74011272 285.13886084 196.19611072\n",
      " 202.26256246 145.38319546 215.02583484 124.55391269  80.17027241\n",
      "  98.99544054  82.02453761  83.40439369 289.99388729 134.33663141\n",
      " 112.1313993  152.32625919 109.90441466 226.28134724 245.74116064\n",
      "  85.56172621 122.28262271 139.20254207 198.95361934 120.92252444\n",
      " 179.99231965 106.43580454 123.03066928  96.46348156  94.96521004\n",
      " 230.01995973 175.10428431  91.2918623  167.79340958 121.57123563\n",
      " 165.20563345 181.26779154  65.1051729   72.81485938 231.35619415\n",
      " 185.78771152 173.68883444 158.22007536 108.88134149 164.4597236\n",
      " 182.06381167 124.68118663 206.58693233 147.68873424 155.35855424\n",
      " 151.40752238 140.07914902  89.42949429 115.09720605]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5341962544929233"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model and make a prediction on the test set. Compare with your implementation\n",
    "##TODO##\n",
    "linear_regression.fit(Xtrain,Ytrain)\n",
    "pred_sklearn_linear = linear_regression.predict(Xtest)\n",
    "print(pred_sklearn_linear)\n",
    "linear_regression.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the perfomance of the regression by plotting your predicted values vs target values on a scatter plot, and drawing a line y=x. If all predictions were perfect, the predicted values would lie on the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted value')"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot predicted values vs target values on a scatter plot, and drawing a line y=x\n",
    "## TODO##\n",
    "print(len(Xtest))\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Ytest, pred_sklearn_linear, label='Data')\n",
    "x_axis = np.linspace(0,300,300)\n",
    "y_axis = x_axis\n",
    "plt.plot(x_axis,y_axis)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('predicted value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra question: Polynomial regression\n",
    "The term 'linear' in linear regression refers only to the coefficients $\\theta$. We can in fact compute polynomial terms in the data and perform linear regression over this extended dataset to get a better fit to the data.\n",
    "\n",
    "To compute polynomial terms in the data automatically, you can use the class `sklearn.preprocessing.PolynomialFeatures`. To find out how to use it, look at the guidance (you can type `help(PolynomialFeatures)` once you have imported it).\n",
    "\n",
    "The following small dataset (in the cell below) gives a relationship between temperature and yield for an experiment. Use cross-validation to select the degree of the polynomial that best fits this data.\n",
    "\n",
    "Plot the mean squared error against degree on the training set and on the validation set. Which degree of polynomial best fits this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = np.array([50,50,50,70,70,70,80,80,80,90,90,90,100,100,100]).reshape(-1, 1)\n",
    "y = np.array([3.3,2.8,2.9,2.3,2.6,2.1,2.5,2.9,2.4,3,3.1,2.8,3.3,3.5,3]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "kf = KFold(n_splits=5, random_state=20, shuffle=True)\n",
    "max_degree = 20\n",
    "degrees = np.arange(2, max_degree + 1)\n",
    "mse_train = [[] for _ in range(max_degree-1)]\n",
    "mse_test = [[] for _ in range(max_degree-1)]\n",
    "for i, degree in enumerate(degrees):\n",
    "    ploy = PolynomialFeatures(degree)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Xtrain, Xtest = X[train_index], X[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "        x_train_fitted = ploy.fit_transform(Xtrain)\n",
    "        x_test_fitted = ploy.fit_transform(Xtest)\n",
    "        linear_regression.fit(x_train_fitted, ytrain)\n",
    "        pred_train = linear_regression.predict(x_train_fitted)\n",
    "        pred_test = linear_regression.predict(x_test_fitted)\n",
    "        mse_train[i].append(metrics.mean_squared_error(ytrain, pred_train))\n",
    "        mse_test[i].append(metrics.mean_squared_error(ytest, pred_test))\n",
    "mean_mse_train = np.mean(mse_train, axis=1)\n",
    "mean_mse_test = np.mean(mse_test, axis=1)\n",
    "plt.plot(np.linspace(2,max_degree, max_degree-1),mean_mse_train)\n",
    "plt.plot(np.linspace(2,max_degree, max_degree-1),mean_mse_test)\n",
    "plt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('mean squard error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
